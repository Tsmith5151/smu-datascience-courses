{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis \n",
    "\n",
    "In this notebook, will demonstrate how to train a word embeddings layer within a recurrent neural network (e.g. LSTM) for sentiment classification. The dataset consist over 10k tweets from the 2016 U.S. Presidential debate. Each tweet is labeled as \"positive\", \"negative\" or \"neutral\". For simplicity, we will remove the \"neutral\" tweets and treat this as a binary classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import  LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=pd.read_csv(\"data/Sentiment.csv\")\n",
    "\n",
    "data=raw[raw['sentiment'] != 'Neutral'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:44 -0700</td>\n",
       "      <td>629697194283499520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.6761</td>\n",
       "      <td>FOX News or Moderators</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:44 -0700</td>\n",
       "      <td>629697192383672320</td>\n",
       "      <td>North Georgia</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   2            Scott Walker                1.0000         yes   \n",
       "1   4  No candidate mentioned                1.0000         yes   \n",
       "2   5            Donald Trump                1.0000         yes   \n",
       "3   6                Ted Cruz                0.6332         yes   \n",
       "4   7  No candidate mentioned                1.0000         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence  \\\n",
       "0                     1.0  Positive                0.6333   \n",
       "1                     1.0  Positive                1.0000   \n",
       "2                     1.0  Positive                0.7045   \n",
       "3                     1.0  Positive                0.6332   \n",
       "4                     1.0  Negative                0.6761   \n",
       "\n",
       "           subject_matter  subject_matter_confidence candidate_gold  ...  \\\n",
       "0       None of the above                     1.0000            NaN  ...   \n",
       "1       None of the above                     0.7039            NaN  ...   \n",
       "2       None of the above                     1.0000            NaN  ...   \n",
       "3       None of the above                     1.0000            NaN  ...   \n",
       "4  FOX News or Moderators                     1.0000            NaN  ...   \n",
       "\n",
       "  relevant_yn_gold retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0              NaN            26             NaN                 NaN   \n",
       "1              NaN           138             NaN                 NaN   \n",
       "2              NaN           156             NaN                 NaN   \n",
       "3              NaN           228             NaN                 NaN   \n",
       "4              NaN            17             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "1  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "2  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "3  RT @GregAbbott_TX: @TedCruz: \"On my first day ...         NaN   \n",
       "4  RT @warriorwoman91: I liked her and was happy ...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "1  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "2  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "3  2015-08-07 09:54:44 -0700  629697194283499520             NaN   \n",
       "4  2015-08-07 09:54:44 -0700  629697192383672320   North Georgia   \n",
       "\n",
       "                user_timezone  \n",
       "0                         NaN  \n",
       "1  Central Time (US & Canada)  \n",
       "2                     Arizona  \n",
       "3  Central Time (US & Canada)  \n",
       "4  Eastern Time (US & Canada)  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data):\n",
    "    words =list(itertools.chain(*[i for i in data['text'].apply(lambda x: x.split()).values]))\n",
    "    return words\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = bag_of_words(data)\n",
    "enc, dec = build_dataset(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "The first thing to do is to create values for our start of sentence, end of sentence, and sentence padding special tokens. We can do this by shifting the encodings to account for the '<pad>' and '<start>' tokens. We will also need to account for that in the decoders. Note: decoder doesn't need shifting, just a map of the proper number. For example, since all the words are off by 2 in the encoder, we can subtract 2 from the encoder result to get the decoder key.However, entries -1 and -2 are not in the decoder, so need to add them in.  <i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enc:\n",
    "    enc[i] = enc[i]+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc['pad']=0\n",
    "enc['<start>']=1\n",
    "dec[-2]='pad'\n",
    "dec[-1]='<start>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Labels + Split Train/Test\n",
    "- For each tweet, split up the tweet into bag of words\n",
    "- Note, we will only be considering binary labels (positive or negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['sentiment'] = le.fit_transform(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(np.floor(data.shape[0]*0.75))\n",
    "train,test = data[0:n],data[n:]\n",
    "\n",
    "# train/test features\n",
    "x_train = list(train.iloc[:,15].apply(lambda x: [enc[i] for i in x.split()]).values)\n",
    "x_test = list(test.iloc[:,15].apply(lambda x: [enc[i] for i in x.split()]).values)\n",
    "\n",
    "# train/test labels\n",
    "y_train,y_test = train.iloc[:,5],test.iloc[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of original tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF…\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoded Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3340, 1242, 3341, 3, 791, 114, 37, 237, 2162, 35, 238, 7, 5570, 226, 1957, 14, 2163, 2164, 826, 9163]\n"
     ]
    }
   ],
   "source": [
    "tmp = [enc[j] for j in train.iloc[0,15].split()]\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall that the decoder was not shifted, so will need to subtract 2 to get the correct word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@ScottWalker:',\n",
       " \"Didn't\",\n",
       " 'catch',\n",
       " 'the',\n",
       " 'full',\n",
       " '#GOPdebate',\n",
       " 'last',\n",
       " 'night.',\n",
       " 'Here',\n",
       " 'are',\n",
       " 'some',\n",
       " 'of',\n",
       " \"Scott's\",\n",
       " 'best',\n",
       " 'lines',\n",
       " 'in',\n",
       " '90',\n",
       " 'seconds.',\n",
       " '#Walker16',\n",
       " 'http://t.co/ZSfF…']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dec[i-2] for i in tmp]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Ideal Length of Tweets:\n",
    "\n",
    "- How would we do this if we had really long tweet lengths?\n",
    "- Plot a histogram and get an idea of where most of the data lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.0\n",
      "24.0\n",
      "25.0\n",
      "27.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tracesmith/.pyenv/versions/3.7.3/envs/smu-nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: scipy.quantile is deprecated and will be removed in SciPy 2.0.0, use numpy.quantile instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(i) for i in x_train]\n",
    "plt.hist(lengths,bins=50)\n",
    "plt.title('Length of Sentences')\n",
    "plt.show()\n",
    "\n",
    "for q in [0.85,0.90,0.95,0.99]:\n",
    "    print(scipy.quantile(lengths,q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad Sequences\n",
    "- Add start of sentence token and then pad sequences (29+1 start token) for a max sequence of 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[[1]+i for i in x_train]\n",
    "x_test=[[1]+i for i in x_test]\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=30)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.asarray(x_train)\n",
    "x_test=np.asarray(x_test)\n",
    "y_train=np.asarray(y_train)\n",
    "y_test=np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model\n",
    "\n",
    "- Simple LSTM Model\n",
    "- Embed each word to 100 dimensions, input length is max_words (30).\n",
    "- Add dropout to help w/ overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train,Y_train,X_test,Y_test,epochs,batch_size,embedding_vector_length,top_words,max_length):\n",
    "    \"\"\" Train LSTM Model w/ Word Embeddings\"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vector_length, input_length=max_length))\n",
    "    model.add(LSTM(100,recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           2562900   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,643,401\n",
      "Trainable params: 2,643,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.4661 - accuracy: 0.8046\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.2122 - accuracy: 0.9160\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.0888 - accuracy: 0.9703\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.0511 - accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.0396 - accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.0324 - accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.0277 - accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.0238 - accuracy: 0.9896\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.0214 - accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.0196 - accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "model = train(x_train,y_train,x_test,y_test,epochs=10,batch_size=64,\n",
    "              embedding_vector_length=100,top_words=len(enc),max_length=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
